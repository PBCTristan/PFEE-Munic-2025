{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier CSV (modifiez 'path_to_file.csv' avec votre propre chemin de fichier)\n",
    "file_path = 'dataMunich/ACCData/device3-2024-09-14T18_29_05.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier dataMunich/ACCData/device3-2024-09-14T18_29_05.csv contient dees données montrant : \n",
      "Prédiction: Crash détecté\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Étape 1: Fonction pour extraire les caractéristiques des données d'entraînement (uniquement l'accéléromètre)\n",
    "def extract_features_train(data):\n",
    "    accel = np.array([entry['accel'] for entry in data])\n",
    "    \n",
    "    # Extraction des caractéristiques (moyenne, écart-type, min, max pour l'accéléromètre)\n",
    "    features = []\n",
    "    features.append(np.mean(accel, axis=0))\n",
    "    features.append(np.std(accel, axis=0))\n",
    "    features.append(np.min(accel, axis=0))\n",
    "    features.append(np.max(accel, axis=0))\n",
    "    \n",
    "    return np.concatenate(features)\n",
    "\n",
    "# Étape 2: Charger les données d'entraînement\n",
    "def load_data(folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            with open(filepath, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "                features = extract_features_train(json_data['data'])  # Utilise uniquement l'accélération\n",
    "                X.append(features)\n",
    "                y.append(1 if json_data['iscrash'] else 0)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Étape 3: Entraînement du modèle\n",
    "folder_path = './dataNous'\n",
    "X, y = load_data(folder_path)\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normaliser/standardiser les caractéristiques\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Entraîner un classificateur (Random Forest dans ce cas)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les probabilités (pour appliquer des seuils ensuite)\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]  # Probabilité pour la classe 'crash'\n",
    "\n",
    "# Fonction pour prédire en fonction d'un seuil\n",
    "def predic_with_threshold(probs, threshold):\n",
    "    return np.array(probs > threshold, dtype=int)\n",
    "\n",
    "# Sélection du meilleur seuil (exemple: 0.7 trouvé plus tôt)\n",
    "threshold = 0.7\n",
    "\n",
    "# Étape 4: Fonction pour extraire les caractéristiques d'un fichier de test CSV\n",
    "def extract_features_from_test(df):\n",
    "    # Utiliser les colonnes X, Y, Z correspondant aux valeurs de l'accélération\n",
    "    accel = df[['X (m/s²)', 'Y (m/s²)', 'Z (m/s²)']].values\n",
    "\n",
    "    # Extraction des caractéristiques (moyenne, écart-type, min, max)\n",
    "    features = []\n",
    "    features.append(np.mean(accel, axis=0))\n",
    "    features.append(np.std(accel, axis=0))\n",
    "    features.append(np.min(accel, axis=0))\n",
    "    features.append(np.max(accel, axis=0))\n",
    "    \n",
    "    return np.concatenate(features)\n",
    "\n",
    "# Étape 5: Pipeline complète pour charger un fichier de test et effectuer une prédiction\n",
    "# file_path = input(\"Entrez le nom du fichier CSV à tester (ex: 'dataMunich/ACCData/device1-2024-08-19T07_34_34.csv') : \")\n",
    "df_test = pd.read_csv(file_path)\n",
    "\n",
    "# Retirer la colonne \"received_at\"\n",
    "df_test = df_test.drop(columns=['received_at','cloud_event_id'])\n",
    "\n",
    "# Simplifier les noms des colonnes commençant par \"MESSAGES\"\n",
    "df_test.columns = [\n",
    "    col.split('.')[-1].replace('ACC_', '') if 'MESSAGES' in col else col\n",
    "    for col in df_test.columns\n",
    "]\n",
    "# Afficher les nouvelles colonnes et quelques lignes pour vérifier\n",
    "# print(df_test.head())\n",
    "\n",
    "# Extraire les caractéristiques des données de test\n",
    "X_test_new = extract_features_from_test(df_test)\n",
    "\n",
    "# Normaliser les nouvelles données de test\n",
    "X_test_new_scaled = scaler.transform([X_test_new])\n",
    "\n",
    "# Prédire les probabilités pour la classe 'iscrash' (1)\n",
    "y_prob_new = clf.predict_proba(X_test_new_scaled)[:, 1]\n",
    "\n",
    "# Appliquer le seuil pour la prédiction\n",
    "y_pred_new = predic_with_threshold(y_prob_new, threshold)\n",
    "\n",
    "# Afficher la prédiction finale\n",
    "if y_pred_new[0] == 1:\n",
    "    print(f\"Le fichier {file_path} contient dees données montrant : \\nPrédiction: Crash détecté\")\n",
    "else:\n",
    "    print(f\"Le fichier {file_path} contient dees données montrant : \\nPrédiction: Pas de crash\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test sur une donnée d'entraînement pour vérification ---\n",
      "Vraie étiquette: Crash\n",
      "Prédiction: Crash détecté\n"
     ]
    }
   ],
   "source": [
    "# Optionnel: Si tu veux vérifier sur une donnée d'entraînement\n",
    "print(\"\\n--- Test sur une donnée d'entraînement pour vérification ---\")\n",
    "random_index = random.randint(0, len(X_train) - 1)\n",
    "X_train_sample = X_train[random_index].reshape(1, -1)\n",
    "y_train_actual = y_train[random_index]\n",
    "\n",
    "y_prob_train_sample = clf.predict_proba(X_train_sample)[:, 1]\n",
    "y_pred_train_sample = predic_with_threshold(y_prob_train_sample, threshold)\n",
    "\n",
    "print(f\"Vraie étiquette: {'Crash' if y_train_actual == 1 else 'Pas de crash'}\")\n",
    "if y_pred_train_sample[0] == 1:\n",
    "    print(\"Prédiction: Crash détecté\")\n",
    "else:\n",
    "    print(\"Prédiction: Pas de crash\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
